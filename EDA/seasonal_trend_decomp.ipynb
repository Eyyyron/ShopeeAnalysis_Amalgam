{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04366bd",
   "metadata": {},
   "source": [
    "# Seasonal and Trend Decomposition Analysis\n",
    "**Dataset:** Shopee Philippines Uncommon Retail Products (March 2022 – November 2025)  \n",
    "**Objective:** Decompose sales patterns into Trend, Seasonal, and Residual components for product and category-level insights.\n",
    "\n",
    "---\n",
    "\n",
    "## Methodology Overview\n",
    "1. **Data Preparation:** Load CSV, parse dates (dd/mm/yyyy format), select metrics\n",
    "2. **Product-Level Processing:** Truncate pre-listing NaNs, filter by duration (≥12 months)\n",
    "3. **Category-Level Aggregation:** Sum sales by category for market analysis\n",
    "4. **Decomposition:** Apply additive model (Y = T + S + R) with 12-month period\n",
    "5. **Metric Extraction:** Calculate seasonal amplitude, trend slope, residual anomalies\n",
    "6. **Visualization:** Plot strategic samples and export results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedb17c0",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ebe7e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d15df9",
   "metadata": {},
   "source": [
    "## 2. Define Cleanup Function\n",
    "Clean up old export files before generating new results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664ea711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup completed. Ready for new exports.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def cleanup_exports():\n",
    "    \"\"\"\n",
    "    Remove old export files and directories before generating new results.\n",
    "    This ensures we always have fresh exports without accumulating old files.\n",
    "    \"\"\"\n",
    "    # Define export paths (relative to notebook location in EDA/)\n",
    "    csv_file = '../seasonal_trend/seasonal_decomposition_results.csv'\n",
    "    viz_base_dir = '../seasonal_trend/visualizations'\n",
    "    \n",
    "    # Remove CSV file if it exists\n",
    "    if os.path.exists(csv_file):\n",
    "        os.remove(csv_file)\n",
    "        print(f\"Removed old file: {csv_file}\")\n",
    "    \n",
    "    # Remove visualizations directory if it exists\n",
    "    if os.path.exists(viz_base_dir):\n",
    "        shutil.rmtree(viz_base_dir)\n",
    "        print(f\"Removed old directory: {viz_base_dir}/\")\n",
    "    \n",
    "    print(\"Cleanup completed. Ready for new exports.\")\n",
    "\n",
    "# Execute cleanup\n",
    "cleanup_exports()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a95d7",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52be91af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: (7554662, 28)\n",
      "\n",
      "Column names:\n",
      "1. product\n",
      "2. time\n",
      "3. avg.sku_price(₱)\n",
      "4. sold/day\n",
      "5. revenue/day(₱)\n",
      "6. sold/m\n",
      "7. product_sales_rate(%)\n",
      "8. price(₱)\n",
      "9. sku\n",
      "10. sold\n",
      "11. sold/month(₱)\n",
      "12. revenue/month\n",
      "13. new_ratings\n",
      "14. ratings\n",
      "15. ratings_rate\n",
      "16. likes\n",
      "17. rating_star\n",
      "18. new_likes\n",
      "19. second-level_category\n",
      "20. third-level_category\n",
      "21. fourth-level_category\n",
      "22. fifth-level_category\n",
      "23. id\n",
      "24. top-level_category\n",
      "25. seller_from\n",
      "26. listing_time\n",
      "27. active_months\n",
      "28. suitable_for_seasonal_analysis\n",
      "\n",
      "First few rows:\n",
      "                                             product        time  \\\n",
      "0     Cute Different Designs  button accessories ...  2022-03-01   \n",
      "1     Cute Different Designs  button accessories ...  2022-04-01   \n",
      "2     Cute Different Designs  button accessories ...  2022-05-01   \n",
      "3     Cute Different Designs  button accessories ...  2022-06-01   \n",
      "4     Cute Different Designs  button accessories ...  2022-07-01   \n",
      "\n",
      "   avg.sku_price(₱)  sold/day  revenue/day(₱)  sold/m  product_sales_rate(%)  \\\n",
      "0               NaN       NaN             NaN     NaN                    NaN   \n",
      "1               NaN       NaN             NaN     NaN                    NaN   \n",
      "2               NaN       NaN             NaN     NaN                    NaN   \n",
      "3               NaN       NaN             NaN     NaN                    NaN   \n",
      "4               NaN       NaN             NaN     NaN                    NaN   \n",
      "\n",
      "   price(₱)  sku  sold  ...   second-level_category  \\\n",
      "0       NaN  NaN   NaN  ...  Additional Accessories   \n",
      "1       NaN  NaN   NaN  ...  Additional Accessories   \n",
      "2       NaN  NaN   NaN  ...  Additional Accessories   \n",
      "3       NaN  NaN   NaN  ...  Additional Accessories   \n",
      "4       NaN  NaN   NaN  ...  Additional Accessories   \n",
      "\n",
      "           third-level_category  fourth-level_category  fifth-level_category  \\\n",
      "0  Charms, Pendants & Ornaments                      -                     -   \n",
      "1  Charms, Pendants & Ornaments                      -                     -   \n",
      "2  Charms, Pendants & Ornaments                      -                     -   \n",
      "3  Charms, Pendants & Ornaments                      -                     -   \n",
      "4  Charms, Pendants & Ornaments                      -                     -   \n",
      "\n",
      "            id   top-level_category  seller_from  listing_time active_months  \\\n",
      "0  17287885303  Fashion Accessories     Overseas    2022-10-18            37   \n",
      "1  17287885303  Fashion Accessories     Overseas    2022-10-18            37   \n",
      "2  17287885303  Fashion Accessories     Overseas    2022-10-18            37   \n",
      "3  17287885303  Fashion Accessories     Overseas    2022-10-18            37   \n",
      "4  17287885303  Fashion Accessories     Overseas    2022-10-18            37   \n",
      "\n",
      "  suitable_for_seasonal_analysis  \n",
      "0                           True  \n",
      "1                           True  \n",
      "2                           True  \n",
      "3                           True  \n",
      "4                           True  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "Data types:\n",
      "product                            object\n",
      "time                               object\n",
      "avg.sku_price(₱)                  float64\n",
      "sold/day                          float64\n",
      "revenue/day(₱)                    float64\n",
      "sold/m                            float64\n",
      "product_sales_rate(%)             float64\n",
      "price(₱)                          float64\n",
      "sku                               float64\n",
      "sold                              float64\n",
      "sold/month(₱)                     float64\n",
      "revenue/month                     float64\n",
      "new_ratings                       float64\n",
      "ratings                           float64\n",
      "ratings_rate                      float64\n",
      "likes                             float64\n",
      "rating_star                       float64\n",
      "new_likes                         float64\n",
      "second-level_category              object\n",
      "third-level_category               object\n",
      "fourth-level_category              object\n",
      "fifth-level_category               object\n",
      "id                                  int64\n",
      "top-level_category                 object\n",
      "seller_from                        object\n",
      "listing_time                       object\n",
      "active_months                       int64\n",
      "suitable_for_seasonal_analysis       bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV dataset\n",
    "df = pd.read_csv('../CSV/consolidated_file_cleaned_v2.csv')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i}. {col}\")\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcda555",
   "metadata": {},
   "source": [
    "## 4. Understand Data Structure\n",
    "Examine the `time` column and identify how the data is organized (already in YYYY-MM-DD format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e8eefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 'time' values:\n",
      "0     2022-03-01\n",
      "1     2022-04-01\n",
      "2     2022-05-01\n",
      "3     2022-06-01\n",
      "4     2022-07-01\n",
      "5     2022-08-01\n",
      "6     2022-09-01\n",
      "7     2022-10-01\n",
      "8     2022-11-01\n",
      "9     2022-12-01\n",
      "10    2023-01-01\n",
      "11    2023-02-01\n",
      "12    2023-03-01\n",
      "13    2023-04-01\n",
      "14    2023-05-01\n",
      "15    2023-06-01\n",
      "16    2023-07-01\n",
      "17    2023-08-01\n",
      "18    2023-09-01\n",
      "19    2023-10-01\n",
      "Name: time, dtype: object\n",
      "\n",
      "Unique time values: 45\n",
      "\n",
      "Time value examples:\n",
      "\n",
      "Unique time values: 45\n",
      "\n",
      "Time value examples:\n",
      "['2022-03-01' '2022-04-01' '2022-05-01' '2022-06-01' '2022-07-01'\n",
      " '2022-08-01' '2022-09-01' '2022-10-01' '2022-11-01' '2022-12-01']\n",
      "\n",
      "Data type of 'time' column: object\n",
      "\n",
      "Checking 'suitable_for_seasonal_analysis' column:\n",
      "suitable_for_seasonal_analysis\n",
      "True     7142715\n",
      "False     411947\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of key columns:\n",
      "['2022-03-01' '2022-04-01' '2022-05-01' '2022-06-01' '2022-07-01'\n",
      " '2022-08-01' '2022-09-01' '2022-10-01' '2022-11-01' '2022-12-01']\n",
      "\n",
      "Data type of 'time' column: object\n",
      "\n",
      "Checking 'suitable_for_seasonal_analysis' column:\n",
      "suitable_for_seasonal_analysis\n",
      "True     7142715\n",
      "False     411947\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of key columns:\n",
      "                                              product        time  sold/m  \\\n",
      "0      Cute Different Designs  button accessories ...  2022-03-01     NaN   \n",
      "1      Cute Different Designs  button accessories ...  2022-04-01     NaN   \n",
      "2      Cute Different Designs  button accessories ...  2022-05-01     NaN   \n",
      "3      Cute Different Designs  button accessories ...  2022-06-01     NaN   \n",
      "4      Cute Different Designs  button accessories ...  2022-07-01     NaN   \n",
      "5      Cute Different Designs  button accessories ...  2022-08-01     NaN   \n",
      "6      Cute Different Designs  button accessories ...  2022-09-01     NaN   \n",
      "7      Cute Different Designs  button accessories ...  2022-10-01     NaN   \n",
      "8      Cute Different Designs  button accessories ...  2022-11-01     0.0   \n",
      "9      Cute Different Designs  button accessories ...  2022-12-01     0.0   \n",
      "10     Cute Different Designs  button accessories ...  2023-01-01  1590.0   \n",
      "11     Cute Different Designs  button accessories ...  2023-02-01  1741.0   \n",
      "12     Cute Different Designs  button accessories ...  2023-03-01  2424.0   \n",
      "13     Cute Different Designs  button accessories ...  2023-04-01  1908.0   \n",
      "14     Cute Different Designs  button accessories ...  2023-05-01  1683.0   \n",
      "15     Cute Different Designs  button accessories ...  2023-06-01  1493.0   \n",
      "16     Cute Different Designs  button accessories ...  2023-07-01  1614.0   \n",
      "17     Cute Different Designs  button accessories ...  2023-08-01     0.0   \n",
      "18     Cute Different Designs  button accessories ...  2023-09-01     0.0   \n",
      "19     Cute Different Designs  button accessories ...  2023-10-01     0.0   \n",
      "\n",
      "    revenue/month   top-level_category  \n",
      "0             NaN  Fashion Accessories  \n",
      "1             NaN  Fashion Accessories  \n",
      "2             NaN  Fashion Accessories  \n",
      "3             NaN  Fashion Accessories  \n",
      "4             NaN  Fashion Accessories  \n",
      "5             NaN  Fashion Accessories  \n",
      "6             NaN  Fashion Accessories  \n",
      "7             NaN  Fashion Accessories  \n",
      "8            0.00  Fashion Accessories  \n",
      "9            0.00  Fashion Accessories  \n",
      "10         122.68  Fashion Accessories  \n",
      "11          13.12  Fashion Accessories  \n",
      "12          39.23  Fashion Accessories  \n",
      "13         -21.28  Fashion Accessories  \n",
      "14         -11.79  Fashion Accessories  \n",
      "15         -11.28  Fashion Accessories  \n",
      "16          -3.90  Fashion Accessories  \n",
      "17           0.00  Fashion Accessories  \n",
      "18           0.00  Fashion Accessories  \n",
      "19           0.00  Fashion Accessories  \n",
      "                                              product        time  sold/m  \\\n",
      "0      Cute Different Designs  button accessories ...  2022-03-01     NaN   \n",
      "1      Cute Different Designs  button accessories ...  2022-04-01     NaN   \n",
      "2      Cute Different Designs  button accessories ...  2022-05-01     NaN   \n",
      "3      Cute Different Designs  button accessories ...  2022-06-01     NaN   \n",
      "4      Cute Different Designs  button accessories ...  2022-07-01     NaN   \n",
      "5      Cute Different Designs  button accessories ...  2022-08-01     NaN   \n",
      "6      Cute Different Designs  button accessories ...  2022-09-01     NaN   \n",
      "7      Cute Different Designs  button accessories ...  2022-10-01     NaN   \n",
      "8      Cute Different Designs  button accessories ...  2022-11-01     0.0   \n",
      "9      Cute Different Designs  button accessories ...  2022-12-01     0.0   \n",
      "10     Cute Different Designs  button accessories ...  2023-01-01  1590.0   \n",
      "11     Cute Different Designs  button accessories ...  2023-02-01  1741.0   \n",
      "12     Cute Different Designs  button accessories ...  2023-03-01  2424.0   \n",
      "13     Cute Different Designs  button accessories ...  2023-04-01  1908.0   \n",
      "14     Cute Different Designs  button accessories ...  2023-05-01  1683.0   \n",
      "15     Cute Different Designs  button accessories ...  2023-06-01  1493.0   \n",
      "16     Cute Different Designs  button accessories ...  2023-07-01  1614.0   \n",
      "17     Cute Different Designs  button accessories ...  2023-08-01     0.0   \n",
      "18     Cute Different Designs  button accessories ...  2023-09-01     0.0   \n",
      "19     Cute Different Designs  button accessories ...  2023-10-01     0.0   \n",
      "\n",
      "    revenue/month   top-level_category  \n",
      "0             NaN  Fashion Accessories  \n",
      "1             NaN  Fashion Accessories  \n",
      "2             NaN  Fashion Accessories  \n",
      "3             NaN  Fashion Accessories  \n",
      "4             NaN  Fashion Accessories  \n",
      "5             NaN  Fashion Accessories  \n",
      "6             NaN  Fashion Accessories  \n",
      "7             NaN  Fashion Accessories  \n",
      "8            0.00  Fashion Accessories  \n",
      "9            0.00  Fashion Accessories  \n",
      "10         122.68  Fashion Accessories  \n",
      "11          13.12  Fashion Accessories  \n",
      "12          39.23  Fashion Accessories  \n",
      "13         -21.28  Fashion Accessories  \n",
      "14         -11.79  Fashion Accessories  \n",
      "15         -11.28  Fashion Accessories  \n",
      "16          -3.90  Fashion Accessories  \n",
      "17           0.00  Fashion Accessories  \n",
      "18           0.00  Fashion Accessories  \n",
      "19           0.00  Fashion Accessories  \n"
     ]
    }
   ],
   "source": [
    "# Examine the time column and data structure\n",
    "print(\"Sample 'time' values:\")\n",
    "print(df['time'].head(20))\n",
    "\n",
    "print(f\"\\nUnique time values: {df['time'].nunique()}\")\n",
    "print(f\"\\nTime value examples:\")\n",
    "print(df['time'].unique()[:10])\n",
    "\n",
    "# Check if time is already datetime or needs parsing\n",
    "print(f\"\\nData type of 'time' column: {df['time'].dtype}\")\n",
    "\n",
    "# Check if suitable_for_seasonal_analysis exists\n",
    "if 'suitable_for_seasonal_analysis' in df.columns:\n",
    "    print(f\"\\nChecking 'suitable_for_seasonal_analysis' column:\")\n",
    "    print(df['suitable_for_seasonal_analysis'].value_counts())\n",
    "\n",
    "# Check data structure - is this wide format or long format?\n",
    "print(f\"\\nSample of key columns:\")\n",
    "print(df[['product', 'time', 'sold/m', 'revenue/month', 'top-level_category']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21666184",
   "metadata": {},
   "source": [
    "## 5. Parse Time Column and Restructure Data\n",
    "Convert time strings to datetime objects and pivot to create time series per product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192b96c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed dates: 7554662 / 7554662\n",
      "Date range: 2022-03-01 00:00:00 to 2025-11-01 00:00:00\n",
      "\n",
      "Unique periods: 45\n",
      "Sample periods: [Period('2022-03', 'M'), Period('2022-04', 'M'), Period('2022-05', 'M'), Period('2022-06', 'M'), Period('2022-07', 'M'), Period('2022-08', 'M'), Period('2022-09', 'M'), Period('2022-10', 'M'), Period('2022-11', 'M'), Period('2022-12', 'M'), Period('2023-01', 'M'), Period('2023-02', 'M')]\n",
      "\n",
      "Data structure (long format - multiple rows per product):\n",
      "\n",
      "Unique periods: 45\n",
      "Sample periods: [Period('2022-03', 'M'), Period('2022-04', 'M'), Period('2022-05', 'M'), Period('2022-06', 'M'), Period('2022-07', 'M'), Period('2022-08', 'M'), Period('2022-09', 'M'), Period('2022-10', 'M'), Period('2022-11', 'M'), Period('2022-12', 'M'), Period('2023-01', 'M'), Period('2023-02', 'M')]\n",
      "\n",
      "Data structure (long format - multiple rows per product):\n",
      "                                              product       date   period  \\\n",
      "0      Cute Different Designs  button accessories ... 2022-03-01  2022-03   \n",
      "1      Cute Different Designs  button accessories ... 2022-04-01  2022-04   \n",
      "2      Cute Different Designs  button accessories ... 2022-05-01  2022-05   \n",
      "3      Cute Different Designs  button accessories ... 2022-06-01  2022-06   \n",
      "4      Cute Different Designs  button accessories ... 2022-07-01  2022-07   \n",
      "5      Cute Different Designs  button accessories ... 2022-08-01  2022-08   \n",
      "6      Cute Different Designs  button accessories ... 2022-09-01  2022-09   \n",
      "7      Cute Different Designs  button accessories ... 2022-10-01  2022-10   \n",
      "8      Cute Different Designs  button accessories ... 2022-11-01  2022-11   \n",
      "9      Cute Different Designs  button accessories ... 2022-12-01  2022-12   \n",
      "10     Cute Different Designs  button accessories ... 2023-01-01  2023-01   \n",
      "11     Cute Different Designs  button accessories ... 2023-02-01  2023-02   \n",
      "12     Cute Different Designs  button accessories ... 2023-03-01  2023-03   \n",
      "13     Cute Different Designs  button accessories ... 2023-04-01  2023-04   \n",
      "14     Cute Different Designs  button accessories ... 2023-05-01  2023-05   \n",
      "\n",
      "    sold/m  revenue/month   top-level_category  \n",
      "0      NaN            NaN  Fashion Accessories  \n",
      "1      NaN            NaN  Fashion Accessories  \n",
      "2      NaN            NaN  Fashion Accessories  \n",
      "3      NaN            NaN  Fashion Accessories  \n",
      "4      NaN            NaN  Fashion Accessories  \n",
      "5      NaN            NaN  Fashion Accessories  \n",
      "6      NaN            NaN  Fashion Accessories  \n",
      "7      NaN            NaN  Fashion Accessories  \n",
      "8      0.0           0.00  Fashion Accessories  \n",
      "9      0.0           0.00  Fashion Accessories  \n",
      "10  1590.0         122.68  Fashion Accessories  \n",
      "11  1741.0          13.12  Fashion Accessories  \n",
      "12  2424.0          39.23  Fashion Accessories  \n",
      "13  1908.0         -21.28  Fashion Accessories  \n",
      "14  1683.0         -11.79  Fashion Accessories  \n",
      "                                              product       date   period  \\\n",
      "0      Cute Different Designs  button accessories ... 2022-03-01  2022-03   \n",
      "1      Cute Different Designs  button accessories ... 2022-04-01  2022-04   \n",
      "2      Cute Different Designs  button accessories ... 2022-05-01  2022-05   \n",
      "3      Cute Different Designs  button accessories ... 2022-06-01  2022-06   \n",
      "4      Cute Different Designs  button accessories ... 2022-07-01  2022-07   \n",
      "5      Cute Different Designs  button accessories ... 2022-08-01  2022-08   \n",
      "6      Cute Different Designs  button accessories ... 2022-09-01  2022-09   \n",
      "7      Cute Different Designs  button accessories ... 2022-10-01  2022-10   \n",
      "8      Cute Different Designs  button accessories ... 2022-11-01  2022-11   \n",
      "9      Cute Different Designs  button accessories ... 2022-12-01  2022-12   \n",
      "10     Cute Different Designs  button accessories ... 2023-01-01  2023-01   \n",
      "11     Cute Different Designs  button accessories ... 2023-02-01  2023-02   \n",
      "12     Cute Different Designs  button accessories ... 2023-03-01  2023-03   \n",
      "13     Cute Different Designs  button accessories ... 2023-04-01  2023-04   \n",
      "14     Cute Different Designs  button accessories ... 2023-05-01  2023-05   \n",
      "\n",
      "    sold/m  revenue/month   top-level_category  \n",
      "0      NaN            NaN  Fashion Accessories  \n",
      "1      NaN            NaN  Fashion Accessories  \n",
      "2      NaN            NaN  Fashion Accessories  \n",
      "3      NaN            NaN  Fashion Accessories  \n",
      "4      NaN            NaN  Fashion Accessories  \n",
      "5      NaN            NaN  Fashion Accessories  \n",
      "6      NaN            NaN  Fashion Accessories  \n",
      "7      NaN            NaN  Fashion Accessories  \n",
      "8      0.0           0.00  Fashion Accessories  \n",
      "9      0.0           0.00  Fashion Accessories  \n",
      "10  1590.0         122.68  Fashion Accessories  \n",
      "11  1741.0          13.12  Fashion Accessories  \n",
      "12  2424.0          39.23  Fashion Accessories  \n",
      "13  1908.0         -21.28  Fashion Accessories  \n",
      "14  1683.0         -11.79  Fashion Accessories  \n"
     ]
    }
   ],
   "source": [
    "# Parse time column - it's already in YYYY-MM-DD format\n",
    "df['date'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "\n",
    "# Check for parsing errors\n",
    "print(f\"Successfully parsed dates: {df['date'].notna().sum()} / {len(df)}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "\n",
    "# Set frequency to Month Start for time series analysis\n",
    "df['period'] = df['date'].dt.to_period('M')\n",
    "\n",
    "print(f\"\\nUnique periods: {df['period'].nunique()}\")\n",
    "print(f\"Sample periods: {sorted(df['period'].unique())[:12]}\")\n",
    "\n",
    "# Display data structure\n",
    "print(f\"\\nData structure (long format - multiple rows per product):\")\n",
    "print(df[['product', 'date', 'period', 'sold/m', 'revenue/month', 'top-level_category']].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca61ed58",
   "metadata": {},
   "source": [
    "## 6. Product-Level Processing: Truncation and Filtering\n",
    "**Step A:** Filter products marked as suitable for seasonal analysis  \n",
    "**Step B:** Create time series per product (pivot from long to wide format)  \n",
    "**Step C:** Truncate pre-listing NaNs and filter by duration (≥12 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce52ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products marked suitable for seasonal analysis: 158437\n",
      "\n",
      "Pivoted data shape: (158437, 45)\n",
      "Products: 158437, Time periods: 45\n",
      "\n",
      "Time periods: [Period('2022-03', 'M'), Period('2022-04', 'M'), Period('2022-05', 'M'), Period('2022-06', 'M'), Period('2022-07', 'M'), Period('2022-08', 'M'), Period('2022-09', 'M'), Period('2022-10', 'M'), Period('2022-11', 'M'), Period('2022-12', 'M'), Period('2023-01', 'M'), Period('2023-02', 'M')]\n",
      "\n",
      "Pivoted data shape: (158437, 45)\n",
      "Products: 158437, Time periods: 45\n",
      "\n",
      "Time periods: [Period('2022-03', 'M'), Period('2022-04', 'M'), Period('2022-05', 'M'), Period('2022-06', 'M'), Period('2022-07', 'M'), Period('2022-08', 'M'), Period('2022-09', 'M'), Period('2022-10', 'M'), Period('2022-11', 'M'), Period('2022-12', 'M'), Period('2023-01', 'M'), Period('2023-02', 'M')]\n",
      "\n",
      "Total products after pivot: 158437\n",
      "Products with ≥12 months data: 158412\n",
      "Filtered out: 25 products\n",
      "\n",
      "Total products after pivot: 158437\n",
      "Products with ≥12 months data: 158412\n",
      "Filtered out: 25 products\n"
     ]
    }
   ],
   "source": [
    "# Step A: Filter products suitable for seasonal analysis\n",
    "if 'suitable_for_seasonal_analysis' in df.columns:\n",
    "    df_filtered = df[df['suitable_for_seasonal_analysis'] == True].copy()\n",
    "    print(f\"Products marked suitable for seasonal analysis: {df_filtered['product'].nunique()}\")\n",
    "else:\n",
    "    df_filtered = df.copy()\n",
    "    print(\"No 'suitable_for_seasonal_analysis' column found, using all products\")\n",
    "\n",
    "# Step B: Pivot data to create time series per product\n",
    "# Primary metric: sold/m (units sold per month)\n",
    "pivot_sold = df_filtered.pivot_table(\n",
    "    index='product',\n",
    "    columns='period',\n",
    "    values='sold/m',\n",
    "    aggfunc='first'  # Use first value if duplicates\n",
    ")\n",
    "\n",
    "# Secondary metric: revenue/month (for validation)\n",
    "pivot_revenue = df_filtered.pivot_table(\n",
    "    index='product',\n",
    "    columns='period',\n",
    "    values='revenue/month',\n",
    "    aggfunc='first'\n",
    ")\n",
    "\n",
    "# Get category mapping\n",
    "product_category = df_filtered.groupby('product')['top-level_category'].first()\n",
    "\n",
    "print(f\"\\nPivoted data shape: {pivot_sold.shape}\")\n",
    "print(f\"Products: {len(pivot_sold)}, Time periods: {len(pivot_sold.columns)}\")\n",
    "print(f\"\\nTime periods: {pivot_sold.columns.tolist()[:12]}\")\n",
    "\n",
    "# Step C: Process each product - truncate and filter\n",
    "processed_products = []\n",
    "\n",
    "for product_id in pivot_sold.index:\n",
    "    # Get time series data\n",
    "    ts_data = pivot_sold.loc[product_id].values\n",
    "    ts_dates = pivot_sold.columns\n",
    "    \n",
    "    # Find first valid (non-NaN) index (listing date)\n",
    "    valid_indices = np.where(~pd.isna(ts_data))[0]\n",
    "    \n",
    "    if len(valid_indices) == 0:\n",
    "        continue  # Skip products with no data\n",
    "    \n",
    "    first_valid_idx = valid_indices[0]\n",
    "    \n",
    "    # Truncate pre-listing NaNs\n",
    "    truncated_data = ts_data[first_valid_idx:]\n",
    "    truncated_dates = ts_dates[first_valid_idx:]\n",
    "    \n",
    "    # Filter by duration (≥12 months)\n",
    "    if len(truncated_data) < 12:\n",
    "        continue\n",
    "    \n",
    "    # Store processed product\n",
    "    processed_products.append({\n",
    "        'product_id': product_id,\n",
    "        'category': product_category.get(product_id, 'Unknown'),\n",
    "        'time_series': truncated_data,\n",
    "        'dates': truncated_dates\n",
    "    })\n",
    "\n",
    "print(f\"\\nTotal products after pivot: {len(pivot_sold)}\")\n",
    "print(f\"Products with ≥12 months data: {len(processed_products)}\")\n",
    "print(f\"Filtered out: {len(pivot_sold) - len(processed_products)} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5663467e",
   "metadata": {},
   "source": [
    "## 7. Category-Level Aggregation (Market Analysis)\n",
    "Sum sales by category to create category-level demand profiles for broad market trend analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec896176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories found: 30\n",
      "\n",
      "Category summary:\n",
      "  Fashion Accessories: 7457 products, 45 months, Total sales: 22010263377\n",
      "  Beauty: 16501 products, 45 months, Total sales: 925950278\n",
      "  Stationery: 10429 products, 45 months, Total sales: 347964820\n",
      "  Computers & Accessories: 1827 products, 45 months, Total sales: 19871788\n",
      "  Women Shoes: 3184 products, 45 months, Total sales: 52932499\n",
      "  Home & Living: 36960 products, 45 months, Total sales: 1304590470\n",
      "  Men Clothes: 4533 products, 45 months, Total sales: 123019610\n",
      "  Motorcycles: 3518 products, 45 months, Total sales: 66752485\n",
      "  Automobiles: 2982 products, 45 months, Total sales: 48809894\n",
      "  Mobile & Gadgets: 9761 products, 45 months, Total sales: 190077070\n",
      "  Audio: 2253 products, 45 months, Total sales: 41234174\n",
      "  Mom & Baby: 6395 products, 45 months, Total sales: 228533838\n",
      "  Baby & Kids Fashion: 5220 products, 45 months, Total sales: 84073527\n",
      "  Sports & Outdoors: 5360 products, 45 months, Total sales: 194324480\n",
      "  Women Clothes: 10469 products, 45 months, Total sales: 242735738\n",
      "  Pets: 5002 products, 45 months, Total sales: 770486294\n",
      "  Home Appliances: 4643 products, 45 months, Total sales: 59744265\n",
      "  Food & Beverages: 3881 products, 45 months, Total sales: 66217446\n",
      "  Hobbies & Collections: 2705 products, 45 months, Total sales: 61199574\n",
      "  Women Bags: 3087 products, 45 months, Total sales: 71338263\n",
      "  Health: 6163 products, 45 months, Total sales: 278744485\n",
      "  Gaming & Consoles: 211 products, 45 months, Total sales: 6408359\n",
      "  Men Shoes: 1490 products, 45 months, Total sales: 28043092\n",
      "  Travel & Luggage: 1560 products, 45 months, Total sales: 34532304\n",
      "  Watches: 672 products, 45 months, Total sales: 9632075\n",
      "  Men Bags: 721 products, 45 months, Total sales: 10268449\n",
      "  Books & Magazines: 451 products, 45 months, Total sales: 7746552\n",
      "  Cameras & Drones: 908 products, 45 months, Total sales: 10601902\n",
      "  Muslim Fashion: 41 products, 45 months, Total sales: 443562\n",
      "  Tickets, Vouchers & Services: 28 products, 45 months, Total sales: 14773730\n"
     ]
    }
   ],
   "source": [
    "# Group products by category and aggregate sales\n",
    "category_aggregates = {}\n",
    "\n",
    "for product in processed_products:\n",
    "    category = product['category']\n",
    "    dates = product['dates']\n",
    "    sales = product['time_series']\n",
    "    \n",
    "    if category not in category_aggregates:\n",
    "        # Initialize category with full date range\n",
    "        # Find the earliest and latest dates across all products in category\n",
    "        category_aggregates[category] = {\n",
    "            'products': [],\n",
    "            'dates_list': []\n",
    "        }\n",
    "    \n",
    "    category_aggregates[category]['products'].append({\n",
    "        'dates': dates,\n",
    "        'sales': sales\n",
    "    })\n",
    "\n",
    "# Aggregate sales for each category\n",
    "for category in category_aggregates:\n",
    "    # Find common date range\n",
    "    all_dates = []\n",
    "    for prod in category_aggregates[category]['products']:\n",
    "        all_dates.extend(prod['dates'].tolist())\n",
    "    \n",
    "    unique_dates = sorted(set(all_dates))\n",
    "    \n",
    "    # Sum sales across products for each date\n",
    "    aggregated_sales = np.zeros(len(unique_dates))\n",
    "    \n",
    "    for prod in category_aggregates[category]['products']:\n",
    "        for i, date in enumerate(unique_dates):\n",
    "            if date in prod['dates']:\n",
    "                idx = prod['dates'].tolist().index(date)\n",
    "                if not pd.isna(prod['sales'][idx]):\n",
    "                    aggregated_sales[i] += prod['sales'][idx]\n",
    "    \n",
    "    category_aggregates[category]['dates'] = pd.PeriodIndex(unique_dates)\n",
    "    category_aggregates[category]['sales'] = aggregated_sales\n",
    "\n",
    "print(f\"Categories found: {len(category_aggregates)}\")\n",
    "print(f\"\\nCategory summary:\")\n",
    "for cat, data in category_aggregates.items():\n",
    "    valid_sales = data['sales'][~pd.isna(data['sales'])]\n",
    "    print(f\"  {cat}: {len(data['products'])} products, {len(data['dates'])} months, \"\n",
    "          f\"Total sales: {np.nansum(valid_sales):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23fd8a",
   "metadata": {},
   "source": [
    "## 8. Seasonal Decomposition - Product Level\n",
    "Apply additive decomposition (Y = T + S + R) to each product with ≥24 months of data (minimum for reliable seasonal decomposition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51dbad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully decomposed 126556 products (≥24 months)\n"
     ]
    }
   ],
   "source": [
    "# Apply seasonal decomposition to products with ≥24 months\n",
    "product_decompositions = []\n",
    "\n",
    "for product in processed_products:\n",
    "    # Require at least 24 months for reliable decomposition\n",
    "    if len(product['time_series']) < 24:\n",
    "        continue\n",
    "    \n",
    "    # Create time series with period index, convert to timestamp for decomposition\n",
    "    dates_timestamp = product['dates'].to_timestamp()\n",
    "    \n",
    "    ts = pd.Series(\n",
    "        product['time_series'],\n",
    "        index=dates_timestamp\n",
    "    )\n",
    "    \n",
    "    # Handle NaN values within the series (interpolate)\n",
    "    ts_filled = ts.interpolate(method='linear', limit_direction='both')\n",
    "    \n",
    "    # Check if we have enough valid data after interpolation\n",
    "    if ts_filled.isna().sum() > len(ts_filled) * 0.3:  # Skip if >30% NaN\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Apply additive decomposition with 12-month period\n",
    "        decomposition = seasonal_decompose(\n",
    "            ts_filled,\n",
    "            model='additive',\n",
    "            period=12,\n",
    "            extrapolate_trend='freq'\n",
    "        )\n",
    "        \n",
    "        product_decompositions.append({\n",
    "            'product_id': product['product_id'],\n",
    "            'category': product['category'],\n",
    "            'original': ts_filled,\n",
    "            'trend': decomposition.trend,\n",
    "            'seasonal': decomposition.seasonal,\n",
    "            'residual': decomposition.resid,\n",
    "            'dates': dates_timestamp\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Decomposition failed for product {product['product_id']}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Successfully decomposed {len(product_decompositions)} products (≥24 months)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af40e55",
   "metadata": {},
   "source": [
    "## 9. Seasonal Decomposition - Category Level\n",
    "Apply decomposition to aggregated category sales for market-level trend analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d627b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully decomposed 30 categories (≥24 months)\n"
     ]
    }
   ],
   "source": [
    "# Apply decomposition to category aggregates with ≥24 months\n",
    "category_decompositions = []\n",
    "\n",
    "for category, cat_data in category_aggregates.items():\n",
    "    # Require at least 24 months for reliable decomposition\n",
    "    if len(cat_data['sales']) < 24:\n",
    "        continue\n",
    "    \n",
    "    # Create time series with timestamp index\n",
    "    dates_timestamp = cat_data['dates'].to_timestamp()\n",
    "    \n",
    "    ts = pd.Series(\n",
    "        cat_data['sales'],\n",
    "        index=dates_timestamp\n",
    "    )\n",
    "    \n",
    "    # Handle NaN values (interpolate)\n",
    "    ts_filled = ts.interpolate(method='linear', limit_direction='both')\n",
    "    \n",
    "    # Check if we have enough valid data\n",
    "    if ts_filled.isna().sum() > len(ts_filled) * 0.3:  # Skip if >30% NaN\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Apply additive decomposition with 12-month period\n",
    "        decomposition = seasonal_decompose(\n",
    "            ts_filled,\n",
    "            model='additive',\n",
    "            period=12,\n",
    "            extrapolate_trend='freq'\n",
    "        )\n",
    "        \n",
    "        category_decompositions.append({\n",
    "            'category': category,\n",
    "            'original': ts_filled,\n",
    "            'trend': decomposition.trend,\n",
    "            'seasonal': decomposition.seasonal,\n",
    "            'residual': decomposition.resid,\n",
    "            'dates': dates_timestamp\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Decomposition failed for category {category}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Successfully decomposed {len(category_decompositions)} categories (≥24 months)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07301c",
   "metadata": {},
   "source": [
    "## 10. Extract Metrics for Product-Level Analysis\n",
    "Calculate key metrics: mean monthly sales, seasonal amplitude, trend slope, and residual anomalies (z-scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8138f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted metrics for 126556 products\n",
      "\n",
      "Metrics summary:\n",
      "       mean_monthly_sales  seasonal_amplitude    trend_slope  \\\n",
      "count       126556.000000       126556.000000  126556.000000   \n",
      "mean           725.692247           18.563135      -8.280920   \n",
      "std           5146.983781           36.406209     229.304348   \n",
      "min              0.000000            0.000000  -27838.214143   \n",
      "25%             59.739766            4.909610     -13.197569   \n",
      "50%            145.642735            8.884173      -2.213184   \n",
      "75%            431.522222           16.234967       4.228130   \n",
      "max         727191.955556          300.000000   25181.185040   \n",
      "\n",
      "       max_residual_zscore  \n",
      "count        126556.000000  \n",
      "mean              4.183368  \n",
      "std               1.285669  \n",
      "min               0.000000  \n",
      "25%               3.254372  \n",
      "50%               4.464622  \n",
      "75%               5.318657  \n",
      "max               5.740880  \n"
     ]
    }
   ],
   "source": [
    "# Extract metrics for each decomposed product\n",
    "product_metrics = []\n",
    "\n",
    "for decomp in product_decompositions:\n",
    "    # Calculate mean monthly sales\n",
    "    mean_monthly_sales = decomp['original'].mean()\n",
    "    \n",
    "    # Calculate seasonal amplitude: (Max(S) - Min(S)) / Mean(T)\n",
    "    seasonal_max = decomp['seasonal'].max()\n",
    "    seasonal_min = decomp['seasonal'].min()\n",
    "    trend_mean = decomp['trend'].mean()\n",
    "    seasonal_amplitude = (seasonal_max - seasonal_min) / trend_mean if trend_mean != 0 else 0\n",
    "    \n",
    "    # Calculate trend slope using linear regression\n",
    "    x = np.arange(len(decomp['trend']))\n",
    "    y = decomp['trend'].values\n",
    "    valid_mask = ~np.isnan(y)\n",
    "    if valid_mask.sum() > 1:\n",
    "        trend_slope, _ = np.polyfit(x[valid_mask], y[valid_mask], 1)\n",
    "    else:\n",
    "        trend_slope = 0\n",
    "    \n",
    "    # Calculate max residual z-score\n",
    "    residuals = decomp['residual'].dropna()\n",
    "    if len(residuals) > 0 and residuals.std() != 0:\n",
    "        residual_zscores = np.abs((residuals - residuals.mean()) / residuals.std())\n",
    "        max_residual_zscore = residual_zscores.max()\n",
    "    else:\n",
    "        max_residual_zscore = 0\n",
    "    \n",
    "    product_metrics.append({\n",
    "        'product': decomp['product_id'],\n",
    "        'category': decomp['category'],\n",
    "        'mean_monthly_sales': mean_monthly_sales,\n",
    "        'seasonal_amplitude': seasonal_amplitude,\n",
    "        'trend_slope': trend_slope,\n",
    "        'max_residual_zscore': max_residual_zscore\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "metrics_df = pd.DataFrame(product_metrics)\n",
    "\n",
    "print(f\"Extracted metrics for {len(metrics_df)} products\")\n",
    "print(f\"\\nMetrics summary:\")\n",
    "print(metrics_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dcbc10",
   "metadata": {},
   "source": [
    "## 11. Export Results to CSV\n",
    "Export the decomposition metrics to CSV for use in subsequent analysis (Task 2.2.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b035a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics exported to '../CSV/seasonal_decomposition_results.csv'\n",
      "Total rows: 126556\n",
      "\n",
      "Columns: ['product', 'category', 'mean_monthly_sales', 'seasonal_amplitude', 'trend_slope', 'max_residual_zscore']\n"
     ]
    }
   ],
   "source": [
    "# Export metrics to CSV\n",
    "output_filename = '../CSV/seasonal_decomposition_results.csv'\n",
    "metrics_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Metrics exported to '{output_filename}'\")\n",
    "print(f\"Total rows: {len(metrics_df)}\")\n",
    "print(f\"\\nColumns: {list(metrics_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb583de6",
   "metadata": {},
   "source": [
    "## 12. Visualization - Strategic Sample Selection\n",
    "Identify products for visualization based on highest seasonal amplitude and residual anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4292b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategic Samples Selected:\n",
      "\n",
      "Top 10 by Seasonal Amplitude:\n",
      "                                                 product           category  \\\n",
      "21073  Adjustable Car Battery Holder Stabilizer Fixed...        Automobiles   \n",
      "49455  GDPLUS BAVIN Waterproof Phone Bag Touch-Screen...   Mobile & Gadgets   \n",
      "71760  Mini LED Candle Light | Flameless Candle Lamp ...      Home & Living   \n",
      "782    (35-125kg)Padded Strapless bra Plus size Bra p...      Women Clothes   \n",
      "2584   1-10Pcs Rice Sub Packaged Boxes / 280ML Refrig...      Home & Living   \n",
      "3617   100*10cmTransparent Sole Protector For Shoe Se...        Women Shoes   \n",
      "9210   20 Color Eyeshadow Palette Sequins Glitter Pea...             Beauty   \n",
      "9372   200*200 Metal Rack Steel Rack Cold-rolled Meta...      Home & Living   \n",
      "10127  20PCS PE Foam Wall Stickers 35*35cm Wall Decal...      Home & Living   \n",
      "11872  3 sa 1 Solar USB Rechargeable LED Camping Ligh...  Sports & Outdoors   \n",
      "\n",
      "       seasonal_amplitude  \n",
      "21073               300.0  \n",
      "49455               300.0  \n",
      "71760               300.0  \n",
      "782                 300.0  \n",
      "2584                300.0  \n",
      "3617                300.0  \n",
      "9210                300.0  \n",
      "9372                300.0  \n",
      "10127               300.0  \n",
      "11872               300.0  \n",
      "\n",
      "Top 10 by Residual Anomalies:\n",
      "                                                 product           category  \\\n",
      "35586  Cetaphil Gentle Skin Cleanser 250ml [For Sensi...             Beauty   \n",
      "67257  Luxe Organix Intensive Whitening Underarm Crea...             Beauty   \n",
      "48047                   Flyman Allen wrench set original      Home & Living   \n",
      "35564  Cetaphil Baby Gentle Cleansing Bar 127g [Hypoa...         Mom & Baby   \n",
      "37684  Compact EWA Fingertip Oximeter with Accurate S...             Health   \n",
      "1930   1 HASSNS Ultra-Light Aluminum Alloy Rigid Bicy...  Sports & Outdoors   \n",
      "2364   1 Sealed Box – 6 Bottles Original Kirkland Min...             Beauty   \n",
      "31336             CETAPHIL Gentle Foaming Cleanser 236ml             Beauty   \n",
      "39305  Cute Waterproof Cartoon Apron – Stylish Kitche...      Home & Living   \n",
      "42225  Door Stop Alarm -Great for Traveling Security ...      Home & Living   \n",
      "\n",
      "       max_residual_zscore  \n",
      "35586             5.740880  \n",
      "67257             5.740003  \n",
      "48047             5.739646  \n",
      "35564             5.739593  \n",
      "37684             5.739591  \n",
      "1930              5.739583  \n",
      "2364              5.739583  \n",
      "31336             5.739583  \n",
      "39305             5.739583  \n",
      "42225             5.739583  \n",
      "\n",
      "Category Representatives (30 categories):\n",
      "                                                  product  \\\n",
      "104816  U19 Earphone Macaron Cartoon Cute Headset 3.5m...   \n",
      "8727    1x T10 W5W lens  Led Flash Strobe Bulb 194 WY5...   \n",
      "94285   Samara PAJAMA TERNO SET for Kids | Cotton Span...   \n",
      "79149   Oil-Based Long-Lasting Good Girl Inspired Perf...   \n",
      "116878  baby books baby book kids education broad book...   \n",
      "56724                       Instax Photo Printing Service   \n",
      "15066   5/10/15/20/30/40/50M CAT5 RJ45 Ethernet cable ...   \n",
      "125849  【clearance sale】2024 KF94 3D Mask KIDS Korea s...   \n",
      "27674   Bear Brand Fortified Powdered Milk Drink 33g S...   \n",
      "2070    1 Pair (2pcs) Gamers Sweatproof Gloves Mobile ...   \n",
      "124766  【Luckiss】 3D Face Mask 10Pcs Korea 3D Face-lif...   \n",
      "123979  【Custom】Acrylic Keychain Standee  stand Keyrin...   \n",
      "13306   3D vinyl Floor sticker ( 91.44* 15.24cm) self ...   \n",
      "113961  ZH Table Clip Fan 4/5 Blades Mini Home Electri...   \n",
      "73716   Mumu 1038 Expansion Card Holder Large-Capacity...   \n",
      "47107               Fashion Taslan Short For Men (UNISEX)   \n",
      "95985    Shoes Shield Anti Wrinkle Shoes Crease Protector   \n",
      "79842   Original Android Super Flash Fast Charge Micro...   \n",
      "3015    10 Pack Facial Tissue Paper Towel 10 Pack Wipe...   \n",
      "47632   Firefly Mini Driving Light White+Yellow Pair o...   \n",
      "67461   M&H ALFARO Instant Hijab Knitted Malaysian Suk...   \n",
      "84313   Petsup Cat Wet Food Real Meat Delish 85g Real ...   \n",
      "5067                             10pcs /pack 3D Face Mask   \n",
      "122245                      ❀◇ Receipt Resibo With Carbon   \n",
      "50818                                       Globe Load 20   \n",
      "104272  Travel Makeup Waterproof Pouch Purse Organizer...   \n",
      "116620    [jden] #159 square stainless steal watch unisex   \n",
      "109858  Waterproof Cartoon mini shrapnel printed lipst...   \n",
      "9977    2025 Sexy Push-Up Bra - Wireless Cotton Bralet...   \n",
      "63316   LALA NEW Korean Fashion Braided strap Ladies f...   \n",
      "\n",
      "                            category  mean_monthly_sales  \n",
      "104816                         Audio        44444.444444  \n",
      "8727                     Automobiles        16070.481481  \n",
      "94285            Baby & Kids Fashion        48554.044444  \n",
      "79149                         Beauty       529510.333333  \n",
      "116878             Books & Magazines        20467.644444  \n",
      "56724               Cameras & Drones         6929.822222  \n",
      "15066        Computers & Accessories         6836.400000  \n",
      "125849           Fashion Accessories       123091.659091  \n",
      "27674               Food & Beverages        25288.533333  \n",
      "2070               Gaming & Consoles        46375.911111  \n",
      "124766                        Health       517985.711111  \n",
      "123979         Hobbies & Collections        40490.464286  \n",
      "13306                  Home & Living       727191.955556  \n",
      "113961               Home Appliances        15998.111111  \n",
      "73716                       Men Bags         7591.790698  \n",
      "47107                    Men Clothes        64298.288889  \n",
      "95985                      Men Shoes        23159.133333  \n",
      "79842               Mobile & Gadgets        86004.000000  \n",
      "3015                      Mom & Baby       329682.535714  \n",
      "47632                    Motorcycles        49309.644444  \n",
      "67461                 Muslim Fashion         1820.475000  \n",
      "84313                           Pets       472365.760000  \n",
      "5067               Sports & Outdoors       156626.727273  \n",
      "122245                    Stationery       176429.232558  \n",
      "50818   Tickets, Vouchers & Services        91899.888889  \n",
      "104272              Travel & Luggage        15610.027778  \n",
      "116620                       Watches         7942.044444  \n",
      "109858                    Women Bags        62173.115385  \n",
      "9977                   Women Clothes       161859.250000  \n",
      "63316                    Women Shoes        25421.266667  \n"
     ]
    }
   ],
   "source": [
    "# Select strategic samples for visualization\n",
    "# Top 10 by seasonal amplitude\n",
    "top_seasonal = metrics_df.nlargest(10, 'seasonal_amplitude')\n",
    "\n",
    "# Top 10 by max residual z-score\n",
    "top_anomaly = metrics_df.nlargest(10, 'max_residual_zscore')\n",
    "\n",
    "# One representative per category (highest mean sales)\n",
    "category_reps = metrics_df.loc[metrics_df.groupby('category')['mean_monthly_sales'].idxmax()]\n",
    "\n",
    "print(\"Strategic Samples Selected:\")\n",
    "print(f\"\\nTop 10 by Seasonal Amplitude:\")\n",
    "print(top_seasonal[['product', 'category', 'seasonal_amplitude']])\n",
    "print(f\"\\nTop 10 by Residual Anomalies:\")\n",
    "print(top_anomaly[['product', 'category', 'max_residual_zscore']])\n",
    "print(f\"\\nCategory Representatives ({len(category_reps)} categories):\")\n",
    "print(category_reps[['product', 'category', 'mean_monthly_sales']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfeb9bd",
   "metadata": {},
   "source": [
    "## 13. Visualize Decomposition for Top Seasonal Products\n",
    "Plot decomposition components (Trend, Seasonal, Residual) for products with highest seasonal amplitude.\n",
    "Each product gets its own separate graph saved in a dedicated directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d27c9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10 seasonal decomposition plots to '../seasonal_trend/visualizations/top_seasonal_products/'\n",
      "Files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create directory for top seasonal products\n",
    "output_dir = '../seasonal_trend/visualizations/top_seasonal_products'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Visualize decomposition for top seasonal products (individual plots)\n",
    "top_seasonal_ids = top_seasonal['product'].head(10).values\n",
    "\n",
    "for product_id in top_seasonal_ids:\n",
    "    # Find decomposition for this product\n",
    "    decomp = next((d for d in product_decompositions if d['product_id'] == product_id), None)\n",
    "    \n",
    "    if decomp is None:\n",
    "        continue\n",
    "    \n",
    "    # Create a 2x2 subplot for this product\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f\"Seasonal Decomposition: {product_id}\", fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot original series\n",
    "    axes[0, 0].plot(decomp['dates'], decomp['original'], color='blue', linewidth=2)\n",
    "    axes[0, 0].set_title('Original Series', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Sales')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot trend\n",
    "    axes[0, 1].plot(decomp['dates'], decomp['trend'], color='green', linewidth=2)\n",
    "    axes[0, 1].set_title('Trend Component', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Trend')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot seasonal\n",
    "    axes[1, 0].plot(decomp['dates'], decomp['seasonal'], color='orange', linewidth=2)\n",
    "    axes[1, 0].set_title('Seasonal Component', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Seasonal')\n",
    "    axes[1, 0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot residual\n",
    "    axes[1, 1].plot(decomp['dates'], decomp['residual'], color='red', linewidth=2)\n",
    "    axes[1, 1].set_title('Residual Component', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Residual')\n",
    "    axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save with sanitized filename\n",
    "    safe_filename = \"\".join(c for c in product_id if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "    safe_filename = safe_filename.replace(' ', '_')[:100]  # Limit length\n",
    "    filepath = os.path.join(output_dir, f'{safe_filename}.png')\n",
    "    plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Saved {len(top_seasonal_ids)} seasonal decomposition plots to '{output_dir}/'\")\n",
    "print(f\"Files saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8fbbf2",
   "metadata": {},
   "source": [
    "## 14. Visualize Decomposition for Top Anomaly Products\n",
    "Plot decomposition with highlighted anomalies for products with highest residual z-scores.\n",
    "Each product gets its own separate graph saved in a dedicated directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2318058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10 anomaly decomposition plots to '../seasonal_trend/visualizations/top_anomaly_products/'\n",
      "Files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create directory for top anomaly products\n",
    "output_dir = '../seasonal_trend/visualizations/top_anomaly_products'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Visualize decomposition for top anomaly products (individual plots)\n",
    "top_anomaly_ids = top_anomaly['product'].head(10).values\n",
    "\n",
    "for product_id in top_anomaly_ids:\n",
    "    # Find decomposition for this product\n",
    "    decomp = next((d for d in product_decompositions if d['product_id'] == product_id), None)\n",
    "    \n",
    "    if decomp is None:\n",
    "        continue\n",
    "    \n",
    "    # Create a 2x2 subplot for this product\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f\"Seasonal Decomposition with Anomalies: {product_id}\", fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot original series\n",
    "    axes[0, 0].plot(decomp['dates'], decomp['original'], color='blue', linewidth=2)\n",
    "    axes[0, 0].set_title('Original Series', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Sales')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot trend\n",
    "    axes[0, 1].plot(decomp['dates'], decomp['trend'], color='green', linewidth=2)\n",
    "    axes[0, 1].set_title('Trend Component', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Trend')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot seasonal\n",
    "    axes[1, 0].plot(decomp['dates'], decomp['seasonal'], color='orange', linewidth=2)\n",
    "    axes[1, 0].set_title('Seasonal Component', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Seasonal')\n",
    "    axes[1, 0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot residual with highlighted anomalies\n",
    "    residuals = decomp['residual']\n",
    "    axes[1, 1].plot(decomp['dates'], residuals, color='red', linewidth=2, alpha=0.6)\n",
    "    \n",
    "    # Highlight anomalies (|z-score| > 2)\n",
    "    if residuals.std() != 0:\n",
    "        z_scores = np.abs((residuals - residuals.mean()) / residuals.std())\n",
    "        anomaly_mask = z_scores > 2\n",
    "        axes[1, 1].scatter(decomp['dates'][anomaly_mask], residuals[anomaly_mask], \n",
    "                          color='darkred', s=100, zorder=5, label='Anomalies (|z| > 2)', marker='*')\n",
    "        axes[1, 1].legend(loc='best')\n",
    "    \n",
    "    axes[1, 1].set_title('Residual Component with Anomalies', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Residual')\n",
    "    axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save with sanitized filename\n",
    "    safe_filename = \"\".join(c for c in product_id if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "    safe_filename = safe_filename.replace(' ', '_')[:100]\n",
    "    filepath = os.path.join(output_dir, f'{safe_filename}.png')\n",
    "    plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Saved {len(top_anomaly_ids)} anomaly decomposition plots to '{output_dir}/'\")\n",
    "print(f\"Files saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6c66d",
   "metadata": {},
   "source": [
    "## 15. Visualize Category-Level Decomposition\n",
    "Plot category-level decompositions for market trend analysis.\n",
    "Each category gets its own separate graph saved in a dedicated directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5814b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 30 category decomposition plots to 'seasonal_trend/visualizations/category_decompositions/'\n",
      "Files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create directory for category-level decompositions\n",
    "output_dir = 'seasonal_trend/visualizations/category_decompositions'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Visualize category-level decompositions (individual plots)\n",
    "if len(category_decompositions) > 0:\n",
    "    for decomp in category_decompositions:\n",
    "        # Create a 2x2 subplot for this category\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle(f\"Category Decomposition: {decomp['category']}\", fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Plot original series\n",
    "        axes[0, 0].plot(decomp['dates'], decomp['original'], color='blue', linewidth=2)\n",
    "        axes[0, 0].set_title('Original Series (Total Sales)', fontsize=12)\n",
    "        axes[0, 0].set_ylabel('Total Sales')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Plot trend\n",
    "        axes[0, 1].plot(decomp['dates'], decomp['trend'], color='green', linewidth=2)\n",
    "        axes[0, 1].set_title('Trend Component', fontsize=12)\n",
    "        axes[0, 1].set_ylabel('Trend')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Plot seasonal\n",
    "        axes[1, 0].plot(decomp['dates'], decomp['seasonal'], color='orange', linewidth=2)\n",
    "        axes[1, 0].set_title('Seasonal Component', fontsize=12)\n",
    "        axes[1, 0].set_ylabel('Seasonal')\n",
    "        axes[1, 0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Plot residual\n",
    "        axes[1, 1].plot(decomp['dates'], decomp['residual'], color='red', linewidth=2, alpha=0.7)\n",
    "        axes[1, 1].set_title('Residual Component', fontsize=12)\n",
    "        axes[1, 1].set_ylabel('Residual')\n",
    "        axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save with sanitized filename\n",
    "        safe_filename = \"\".join(c for c in decomp['category'] if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "        safe_filename = safe_filename.replace(' ', '_')[:100]\n",
    "        filepath = os.path.join(output_dir, f'{safe_filename}.png')\n",
    "        plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"Saved {len(category_decompositions)} category decomposition plots to '{output_dir}/'\")\n",
    "    print(f\"Files saved successfully!\")\n",
    "else:\n",
    "    print(\"No category decompositions available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1605a5ab",
   "metadata": {},
   "source": [
    "## 16. Seasonal Subseries Plot (Calendar View)\n",
    "Visualize seasonal patterns across years for representative products.\n",
    "Each product gets its own separate graph saved in a dedicated directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5f2d9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10 seasonal subseries plots to '../seasonal_trend/visualizations/seasonal_subseries/'\n",
      "Files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create directory for seasonal subseries plots\n",
    "output_dir = '../seasonal_trend/visualizations/seasonal_subseries'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create seasonal subseries plots for top seasonal products\n",
    "def plot_seasonal_subseries(decomp, title, output_path):\n",
    "    \"\"\"Plot seasonal pattern by month across years\"\"\"\n",
    "    df_plot = pd.DataFrame({\n",
    "        'date': decomp['dates'],\n",
    "        'value': decomp['original'].values\n",
    "    })\n",
    "    df_plot['year'] = df_plot['date'].dt.year\n",
    "    df_plot['month'] = df_plot['date'].dt.month\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Plot each year as a separate line\n",
    "    for year in sorted(df_plot['year'].unique()):\n",
    "        year_data = df_plot[df_plot['year'] == year]\n",
    "        ax.plot(year_data['month'], year_data['value'], \n",
    "               marker='o', label=str(year), linewidth=2, markersize=6)\n",
    "    \n",
    "    ax.set_xlabel('Month', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Sales', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(range(1, 13))\n",
    "    ax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "    ax.legend(title='Year', bbox_to_anchor=(1.05, 1), loc='upper left', frameon=True)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Plot for top seasonal products\n",
    "top_for_subseries = top_seasonal['product'].head(10).values\n",
    "\n",
    "for product_id in top_for_subseries:\n",
    "    decomp = next((d for d in product_decompositions if d['product_id'] == product_id), None)\n",
    "    if decomp:\n",
    "        # Sanitize filename\n",
    "        safe_filename = \"\".join(c for c in product_id if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "        safe_filename = safe_filename.replace(' ', '_')[:100]\n",
    "        filepath = os.path.join(output_dir, f'{safe_filename}.png')\n",
    "        \n",
    "        plot_seasonal_subseries(decomp, f\"Seasonal Subseries - {product_id}\", filepath)\n",
    "\n",
    "print(f\"Saved {len(top_for_subseries)} seasonal subseries plots to '{output_dir}/'\")\n",
    "print(f\"Files saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c00df0",
   "metadata": {},
   "source": [
    "## 17. Summary and Interpretation\n",
    "Review key findings from the seasonal decomposition analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d1e7a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SEASONAL DECOMPOSITION ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "1. DATA PROCESSING:\n",
      "   - Total products in dataset: 7554662\n",
      "   - Products with ≥12 months: 158412\n",
      "   - Products decomposed (≥24 months): 126556\n",
      "   - Categories analyzed: 30\n",
      "\n",
      "2. TOP PRODUCTS BY SEASONAL AMPLITUDE:\n",
      "   (Strong seasonal patterns - inventory optimization opportunities)\n",
      "   Adjustable Car Battery Holder Stabilizer Fixed Bra | Amplitude: 300.000\n",
      "   GDPLUS BAVIN Waterproof Phone Bag Touch-Screen Und | Amplitude: 300.000\n",
      "   Mini LED Candle Light | Flameless Candle Lamp | We | Amplitude: 300.000\n",
      "   (35-125kg)Padded Strapless bra Plus size Bra push  | Amplitude: 300.000\n",
      "   1-10Pcs Rice Sub Packaged Boxes / 280ML Refrigerat | Amplitude: 300.000\n",
      "\n",
      "3. TOP PRODUCTS BY TREND SLOPE:\n",
      "   (Emerging interest - growing demand)\n",
      "   3D vinyl Floor sticker ( 91.44* 15.24cm) self adhe | Slope: 25181.185\n",
      "   3D Self-Adhesive Wallpaper Continuous Waterproof B | Slope: 10672.797\n",
      "   Petsup Cat Wet Food Real Meat Delish 85g Real Chic | Slope: 10633.470\n",
      "   ❀◇ Receipt Resibo With Carbon                      | Slope: 7926.994\n",
      "   3D Vinyl Floor Sticker With Waterproof PVC and Sel | Slope: 7082.504\n",
      "\n",
      "4. TOP PRODUCTS BY RESIDUAL ANOMALIES:\n",
      "   (Viral events or short-term consumer surges)\n",
      "   Cetaphil Gentle Skin Cleanser 250ml [For Sensitive | Max Z-Score: 5.74\n",
      "   Luxe Organix Intensive Whitening Underarm Cream 10 | Max Z-Score: 5.74\n",
      "   Flyman Allen wrench set original                   | Max Z-Score: 5.74\n",
      "   Cetaphil Baby Gentle Cleansing Bar 127g [Hypoaller | Max Z-Score: 5.74\n",
      "   Compact EWA Fingertip Oximeter with Accurate SpO2  | Max Z-Score: 5.74\n",
      "\n",
      "5. CATEGORY-LEVEL INSIGHTS:\n",
      "   Fashion Accessories            | Trend Slope: 32203195.33 | Seasonal Amp: 9.732\n",
      "   Beauty                         | Trend Slope: 635248.43 | Seasonal Amp: 5.490\n",
      "   Stationery                     | Trend Slope: 212167.00 | Seasonal Amp: 2.004\n",
      "   Computers & Accessories        | Trend Slope:  6289.96 | Seasonal Amp: 1.434\n",
      "   Women Shoes                    | Trend Slope:    54.45 | Seasonal Amp: 0.968\n",
      "   Home & Living                  | Trend Slope: 505728.13 | Seasonal Amp: 3.528\n",
      "   Men Clothes                    | Trend Slope: 16761.83 | Seasonal Amp: 0.979\n",
      "   Motorcycles                    | Trend Slope: 43131.25 | Seasonal Amp: 2.225\n",
      "   Automobiles                    | Trend Slope: 40713.32 | Seasonal Amp: 1.307\n",
      "   Mobile & Gadgets               | Trend Slope: 23783.22 | Seasonal Amp: 2.179\n",
      "   Audio                          | Trend Slope:  7152.25 | Seasonal Amp: 1.569\n",
      "   Mom & Baby                     | Trend Slope: 81575.89 | Seasonal Amp: 3.094\n",
      "   Baby & Kids Fashion            | Trend Slope: 15867.24 | Seasonal Amp: 1.003\n",
      "   Sports & Outdoors              | Trend Slope: 114764.24 | Seasonal Amp: 4.136\n",
      "   Women Clothes                  | Trend Slope: 17156.34 | Seasonal Amp: 0.917\n",
      "   Pets                           | Trend Slope: 119314.25 | Seasonal Amp: 45.188\n",
      "   Home Appliances                | Trend Slope:  7944.90 | Seasonal Amp: 0.868\n",
      "   Food & Beverages               | Trend Slope: 22065.79 | Seasonal Amp: 0.986\n",
      "   Hobbies & Collections          | Trend Slope: 23375.75 | Seasonal Amp: 0.609\n",
      "   Women Bags                     | Trend Slope:  8321.47 | Seasonal Amp: 2.878\n",
      "   Health                         | Trend Slope: -146738.51 | Seasonal Amp: 1.013\n",
      "   Gaming & Consoles              | Trend Slope:  -866.58 | Seasonal Amp: 1.636\n",
      "   Men Shoes                      | Trend Slope: 11587.57 | Seasonal Amp: 0.774\n",
      "   Travel & Luggage               | Trend Slope:  9764.99 | Seasonal Amp: 1.925\n",
      "   Watches                        | Trend Slope:  3239.03 | Seasonal Amp: 2.492\n",
      "   Men Bags                       | Trend Slope:  1321.05 | Seasonal Amp: 1.615\n",
      "   Books & Magazines              | Trend Slope:  2322.31 | Seasonal Amp: 2.446\n",
      "   Cameras & Drones               | Trend Slope:  1773.17 | Seasonal Amp: 0.602\n",
      "   Muslim Fashion                 | Trend Slope:   742.01 | Seasonal Amp: 1.452\n",
      "   Tickets, Vouchers & Services   | Trend Slope: -24551.40 | Seasonal Amp: 2.658\n",
      "\n",
      "6. OUTPUT FILES GENERATED:\n",
      "   - seasonal_trend/seasonal_decomposition_results.csv (metrics for 126556 products)\n",
      "   - seasonal_trend/visualizations/top_seasonal_products/ (individual product plots)\n",
      "   - seasonal_trend/visualizations/top_anomaly_products/ (individual anomaly plots)\n",
      "   - seasonal_trend/visualizations/category_decompositions/ (individual category plots)\n",
      "   - seasonal_trend/visualizations/seasonal_subseries/ (individual subseries plots)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate summary report\n",
    "print(\"=\"*80)\n",
    "print(\"SEASONAL DECOMPOSITION ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. DATA PROCESSING:\")\n",
    "print(f\"   - Total products in dataset: {len(df)}\")\n",
    "print(f\"   - Products with ≥12 months: {len(processed_products)}\")\n",
    "print(f\"   - Products decomposed (≥24 months): {len(product_decompositions)}\")\n",
    "print(f\"   - Categories analyzed: {len(category_decompositions)}\")\n",
    "\n",
    "print(f\"\\n2. TOP PRODUCTS BY SEASONAL AMPLITUDE:\")\n",
    "print(f\"   (Strong seasonal patterns - inventory optimization opportunities)\")\n",
    "for i, row in top_seasonal.head(5).iterrows():\n",
    "    print(f\"   {row['product'][:50]:50s} | Amplitude: {row['seasonal_amplitude']:.3f}\")\n",
    "\n",
    "print(f\"\\n3. TOP PRODUCTS BY TREND SLOPE:\")\n",
    "top_trending = metrics_df.nlargest(5, 'trend_slope')\n",
    "print(f\"   (Emerging interest - growing demand)\")\n",
    "for i, row in top_trending.iterrows():\n",
    "    print(f\"   {row['product'][:50]:50s} | Slope: {row['trend_slope']:.3f}\")\n",
    "\n",
    "print(f\"\\n4. TOP PRODUCTS BY RESIDUAL ANOMALIES:\")\n",
    "print(f\"   (Viral events or short-term consumer surges)\")\n",
    "for i, row in top_anomaly.head(5).iterrows():\n",
    "    print(f\"   {row['product'][:50]:50s} | Max Z-Score: {row['max_residual_zscore']:.2f}\")\n",
    "\n",
    "print(f\"\\n5. CATEGORY-LEVEL INSIGHTS:\")\n",
    "for decomp in category_decompositions:\n",
    "    trend_slope_cat = np.polyfit(range(len(decomp['trend'])), \n",
    "                                  decomp['trend'].fillna(method='ffill').values, 1)[0]\n",
    "    seasonal_amp_cat = (decomp['seasonal'].max() - decomp['seasonal'].min()) / decomp['trend'].mean()\n",
    "    print(f\"   {decomp['category']:30s} | Trend Slope: {trend_slope_cat:8.2f} | \"\n",
    "          f\"Seasonal Amp: {seasonal_amp_cat:.3f}\")\n",
    "\n",
    "print(f\"\\n6. OUTPUT FILES GENERATED:\")\n",
    "print(f\"   - seasonal_trend/seasonal_decomposition_results.csv (metrics for {len(metrics_df)} products)\")\n",
    "print(f\"   - seasonal_trend/visualizations/top_seasonal_products/ (individual product plots)\")\n",
    "print(f\"   - seasonal_trend/visualizations/top_anomaly_products/ (individual anomaly plots)\")\n",
    "print(f\"   - seasonal_trend/visualizations/category_decompositions/ (individual category plots)\")\n",
    "print(f\"   - seasonal_trend/visualizations/seasonal_subseries/ (individual subseries plots)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
